manifest {
  name = 'ScaleCROP'
  version = '1.0.0'
  description = 'ScaleBio CROP-seq analysis workflow'
  homePage = 'https://scale.bio'
}


//// Parameter defaults; Can be set at workflow runtime on the nextflow command-line
// See nextflow_schema.json for description
params {
    help = false
    show_hidden_params = false
    
    //// Sequencing data input.
    // Either a runfolder (BCL) or a directory with fastq files is required!
    runFolder = null
    fastqDir = null 
    fastqSamplesheet = null // Optional
    
    //// Sample sheet, i.e. path to samples.csv (required!)
    samples = null

    //// Output options
    outDir = "ScaleCROP.out" // Workflow output directory
    fastqOut = false // set to true to publish demultiplexed fastq files to outDir

    //// Library structure (barcode locations and sequences).
    // Can be absolute paths or relative to ${projectDir}/references/
    libStructure = "libV1.json"
    libTemplate = "libGuideSeq.TEMPLATE.json"

    //// Guide and ScaleRna allCells input folders (file names contained within are referenced in samples.csv)
    allCellsDir = null
    guidesDir = null

    //// Optional workflow parameters
    thresh = 3
    
    
    splitFastq = false // Split library fastq by PCR well for parallelization
    bclConvertParams = "" //"--bcl-only-lane 1" // Only use lane 1
    fastqc = true // Run fastqc on input fastqs

    starFeature = "GeneFull_Ex50pAS" // What read to transcript overlaps STAR counts (--soloFeatures)
    starMulti = "PropUnique" // How to handle reads matching multiple genes (--soloMultiMappers)
    starStrand = "Forward"
    
    starTrimming = "" // "--clipAdapterType CellRanger4" // PolyA trimming in STAR
    trimFastq = false // PolyA trimming with cutadapt
    trimAdapt = "-a A{8}N{100} -a T{8}N{100}" // Adapters to trim with cutadapt

    //// Resources and parallelization 
    // Max. resources that can be requested for a single task / process
    task_max_memory = 60.GB
    task_max_cpus = 12

}

process {
    errorStrategy = 'retry'
    maxRetries = 1

    cpus = { max_cpu(2) }
    memory = { max_mem(4.GB * task.attempt) }
    time = 48.h

    container = "felixschlesinger/scalerna@sha256:b333af2e72f69c2c9cbdb6587d04a93d9d4016c3b03eb30e37557a54284119f6"

    withLabel: small {
        cpus = 1
        memory = { max_mem(2.GB * task.attempt) }
    }
    withName:bclconvert {
        container = 'felixschlesinger/bclconvert'
        cpus = { max_cpu(24) }
        memory = { max_mem(32.GB * task.attempt) }
    }
    withName:fastqc {
        container = 'biocontainers/fastqc:v0.11.9_cv8'
    }
    withName:trimFq {
	    cpus = { max_cpu(4) }
	    memory = { max_mem(2.GB * task.attempt) }
    }
    withName:barcodeParser {
        cpus = { max_cpu(6) }
        memory = { max_mem(6.GB * task.attempt) }
    }
    withName:barcode_assignment {
        cpus = { max_cpu(6) } 
        memory = { max_mem(6.GB * task.attempt) }
    }
    withName:qcGuideinput {
        container = 'public.ecr.aws/o5l3p3e4/scalecrop:latest'
        cpus = { 1 * task.attempt }
        memory = { max_mem(6.GB * task.attempt) }
    }
    withName:count_guides {
        container = 'public.ecr.aws/o5l3p3e4/scalecrop:latest'
        cpus = { 2 * task.attempt }
        memory = { max_mem(6.GB * task.attempt) }
    }
    withName:crop_analysis {
        container = 'public.ecr.aws/o5l3p3e4/scalecrop:latest'
        cpus = { 3 * task.attempt }
        memory = { max_mem(6.GB * task.attempt) }
    }
}
profiles {
  conda {
    conda.enabled = true
    process.conda = "$projectDir/envs/scaleRna.conda.yml"
    process {
      withLabel:crispr {
        conda = "$projectDir/envs/scaleCROP_verbose.conda.yml"
      }
    }
  }
  docker {
    // Shared settings for all container engines go here
    docker.enabled = true
    docker.fixOwnership = true
    // docker.runOptions = '-u $(id -u):$(id -g)' // Alt. to fixOwnership; match user ID in container to outside
  }
  singularity {
    singularity.enabled = true 
    singularity.autoMounts = true
    docker.enabled = false
  }
  podman {
    podman.enabled = true 
    docker.enabled = false
  }
}
conda.createTimeout = '1 h'

// nf-core functions to ensure that resource requirements don't go 
// beyond a maximum limit
def max_mem(obj) {
    if (obj.compareTo(params.task_max_memory as nextflow.util.MemoryUnit) == 1)
        return params.task_max_memory as nextflow.util.MemoryUnit
    else
        return obj
}
def max_cpu(obj) {
    return Math.min(obj, params.task_max_cpus as int)
}
